---
title: "Random Forest (Decision Trees)"
author: "Victor Richerson"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

This is an introduction to Random Forests.  Random forests are ensembles of decision trees that incorporate a randomization feature to increase predictive accuracy.  The method is attributed to Dr. Leo Breiman [@Breiman2001] of the University of Berkeley in California.  Dr. Breiman is well known and has prior work with Classification and Regression Trees, a textbook on decision tree methodology.  Dr. Breiman previously worked on expanding decision trees with the Bagging Predictors methodology [@Breiman1996] and was exposed to the work of other researchers with the AdaBoost (adaptive boosting) methodology.  The random forest methodology has a basis in randomization ideas presented by Thomas G. Dietterich of Oregon State University [@Dietterich2000].  The random forest method of using ensembles of randomized decision trees has been a popular research topic with many other researchers looking into ways to expand on and improve the method.  "Rotation Forest" was a method to incorporate random forest with PCA to create new features [@Rodriguez2006].  This method was just one of many to follow on and improve the original random forest methodology.

<!--
This is an introduction to Kernel regression, which is a non-parametric
estimator that estimates the conditional expectation of two variables
which is random. The goal of a kernel regression is to discover the
non-linear relationship between two random variables. To discover the
non-linear relationship, kernel estimator or kernel smoothing is the
main method to estimate the curve for non-parametric statistics. In
kernel estimator, weight function is known as kernel function
[@efr2008]. Cite this paper [@bro2014principal]. The GEE [@wang2014].
-->

## Methods

<!--
The common non-parametric regression model is
$Y_i = m(X_i) + \varepsilon_i$, where $Y_i$ can be defined as the sum of
the regression function value $m(x)$ for $X_i$. Here $m(x)$ is unknown
and $\varepsilon_i$ some errors. With the help of this definition, we
can create the estimation for local averaging i.e. $m(x)$ can be
estimated with the product of $Y_i$ average and $X_i$ is near to $x$. In
other words, this means that we are discovering the line through the
data points with the help of surrounding data points. The estimation
formula is printed below [@R-base]:

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$ $W_n(x)$ is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if $X_i$ is far from $x$.
-->

## Analysis and Results

### Data and Vizualisation

<!--
A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```
-->

### Statistical Modeling

### Conlusion

## References

<!--
@article{wang2014,
  title={Generalized estimating equations in longitudinal data analysis: a review and recent developments},
  author={Wang, Ming},
  journal={Advances in Statistics},
  volume={2014},
  year={2014},
  publisher={Hindawi}
}

@Manual{R-base,
  title = {R: A Language and Environment for Statistical
           Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2019},
  url = {https://www.R-project.org},
}

@book{efr2008,
  title={Nonparametric Curve Estimation: Methods, Theory, and Applications},
  author={Efromovich, S.},
  isbn={9780387226385},
  lccn={99013253},
  series={Springer Series in Statistics},
  url={https://books.google.com/books?id=mdoLBwAAQBAJ},
  year={2008},
  publisher={Springer New York}
}
@article{bro2014principal,
  title={Principal component analysis},
  author={Bro, Rasmus and Smilde, Age K},
  journal={Analytical methods},
  volume={6},
  number={9},
  pages={2812--2831},
  year={2014},
  publisher={Royal Society of Chemistry}
}
-->